{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF-Extraction and Data Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Corresponding spec of the project__: <BR>\n",
    "This notebook uses the introductory code provided by Jon to start the extraction process of our unstructured text data for the rest of the project. <BR>\n",
    "The parts of the spec that this notebook should cover are: <BR>\n",
    "* __Data Annotation__:\n",
    "    - Process PDF files to a structured data format\n",
    "    - Label sections of the extracted text with location data (e.g. page number, section heading, etc.)\n",
    "    - Document annotation methodology <br>\n",
    "    __Course Reference: W7 Lab - Text Extraction Methods, W8 Lab - Document Chunking__\n",
    "\n",
    "* __Quality Assurance__:\n",
    "    - Validate consistency (üèÜ)\n",
    "    - Handle edge cases (üèÜ) <BR>\n",
    "    __Course Reference: W8 Lab - Exploratory Quality Assurance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/notebooks/utils.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import importlib\n",
    "import utils \n",
    "\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying PDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all files\n",
    "\n",
    "# Glob all files under ../data/pdfs/\n",
    "#Here we use the glob module which is used to find files based on patterns (note the * to denote all files within the pdfs folder) crucially we are saving the file paths to the files variable and not the actual files themselves\n",
    "\n",
    "files = glob.glob('../data/pdfs/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing PDFs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IGNORE (To aid own understanding)\n",
    "The below function is what we use to create our initial dictionary of doc names and their respective text. Starting from the back of the function, the list comprehension retrieves each file path for all the pds file paths which we stored in the files variable above. For each file, we create a key-value pair, in which the base_name i.e. the actual name of the file stripped of the path is the key and using the extract_text_data_from_pdf function from utils, we store the actual text data. Note that this function uses the unstructure package to do the heavy lifting in terms of the actual text extraction, but with additional functionality for correctly formatting, cleaning the extracted text. Inclusion of metadata is a crucial addition here since we now get additional context for each pdf such as page numbers, . As seen in the cell output below, for some pdfs the function is unable to read and so omitts(I assume this is fine since the function handles and skips pdfs where this occurs). So what partition_pdf is doing is processign different elements of the pdf - and then populating them with the relevant tags/metadata in a dict, and then appending said dict to a list which is the value for each pdf. So in that way for each key (pdf name), we have a list as the value - and the entire contents of that list span the text from the pdf - with associated relevant information for each element. <BR>\n",
    "\n",
    "Note on the pdf_partition function: <BR>\n",
    "* So the function below splits parts of the pdf into elements due to the pdf_partition function. The split is done according to the parts of the document that the respective words/sections/sentences correpond to - e.g. title, table, text etc.\n",
    "* So this is not tokenising per se, we still need to perform tokenisation after this\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The below function is currently encountering one error when processing the pdfs because of invalid dictionary constructs. This means that pdfminer is failing to extract the text. Some pdfs contain non-standard or corrupted meta-data which is what may be causing the issue <BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6f1a29709d4667a8385449c111ad6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Invalid dictionary construct: [/'CS', /'DeviceCMYK', /'I', False, /'K', /b'fals', /b'e', /'S', /'Transparency', /'Type', /'Group']\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 251, in partition_pdf_or_image\n",
      "    extracted_elements = extractable_elements(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 196, in extractable_elements\n",
      "    return _partition_pdf_with_pdfminer(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/utils.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 489, in _partition_pdf_with_pdfminer\n",
      "    elements = _process_pdfminer_pages(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 562, in _process_pdfminer_pages\n",
      "    interpreter.process_page(page)\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfinterp.py\", line 997, in process_page\n",
      "    self.render_contents(page.resources, page.contents, ctm=ctm)\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfinterp.py\", line 1014, in render_contents\n",
      "    self.init_resources(resources)\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 541, in pdfminer_interpreter_init_resources\n",
      "    return wrapped(resources)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfinterp.py\", line 383, in init_resources\n",
      "    spec = dict_value(spec)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdftypes.py\", line 185, in dict_value\n",
      "    x = resolve1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdftypes.py\", line 96, in resolve1\n",
      "    x = x.resolve(default=default)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdftypes.py\", line 84, in resolve\n",
      "    return self.doc.getobj(self.objid)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfdocument.py\", line 860, in getobj\n",
      "    obj = self._getobj_objstm(stream, index, objid)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfdocument.py\", line 780, in _getobj_objstm\n",
      "    (objs, n) = self._get_objects(stream)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfdocument.py\", line 806, in _get_objects\n",
      "    (_, obj) = parser.nextobject()\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/psparser.py\", line 624, in nextobject\n",
      "    raise PSSyntaxError(error_msg)\n",
      "pdfminer.psexceptions.PSSyntaxError: Invalid dictionary construct: [/'CS', /'DeviceCMYK', /'I', False, /'K', /b'fals', /b'e', /'S', /'Transparency', /'Type', /'Group']\n",
      "PDF text extraction failed, skip text extraction...\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "No /Root object! - Is this really a PDF?\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 251, in partition_pdf_or_image\n",
      "    extracted_elements = extractable_elements(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 196, in extractable_elements\n",
      "    return _partition_pdf_with_pdfminer(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/utils.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 489, in _partition_pdf_with_pdfminer\n",
      "    elements = _process_pdfminer_pages(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 561, in _process_pdfminer_pages\n",
      "    for i, page in enumerate(PDFPage.get_pages(fp)):  # type: ignore\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfpage.py\", line 154, in get_pages\n",
      "    doc = PDFDocument(parser, password=password, caching=caching)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfdocument.py\", line 748, in __init__\n",
      "    raise PDFSyntaxError(\"No /Root object! - Is this really a PDF?\")\n",
      "pdfminer.pdfparser.PDFSyntaxError: No /Root object! - Is this really a PDF?\n",
      "PDF text extraction failed, skip text extraction...\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "No /Root object! - Is this really a PDF?\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 251, in partition_pdf_or_image\n",
      "    extracted_elements = extractable_elements(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 196, in extractable_elements\n",
      "    return _partition_pdf_with_pdfminer(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/utils.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 489, in _partition_pdf_with_pdfminer\n",
      "    elements = _process_pdfminer_pages(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 561, in _process_pdfminer_pages\n",
      "    for i, page in enumerate(PDFPage.get_pages(fp)):  # type: ignore\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfpage.py\", line 154, in get_pages\n",
      "    doc = PDFDocument(parser, password=password, caching=caching)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfdocument.py\", line 748, in __init__\n",
      "    raise PDFSyntaxError(\"No /Root object! - Is this really a PDF?\")\n",
      "pdfminer.pdfparser.PDFSyntaxError: No /Root object! - Is this really a PDF?\n",
      "PDF text extraction failed, skip text extraction...\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "The PDF <_io.BufferedReader name='../data/pdfs/ethiopia_english_20220601.pdf'> contains a metadata field indicating that it should not allow text extraction. Ignoring this field and proceeding. Use the check_extractable if you want to raise an error in this case\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "No /Root object! - Is this really a PDF?\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 251, in partition_pdf_or_image\n",
      "    extracted_elements = extractable_elements(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 196, in extractable_elements\n",
      "    return _partition_pdf_with_pdfminer(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/utils.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 489, in _partition_pdf_with_pdfminer\n",
      "    elements = _process_pdfminer_pages(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 561, in _process_pdfminer_pages\n",
      "    for i, page in enumerate(PDFPage.get_pages(fp)):  # type: ignore\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfpage.py\", line 154, in get_pages\n",
      "    doc = PDFDocument(parser, password=password, caching=caching)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfdocument.py\", line 748, in __init__\n",
      "    raise PDFSyntaxError(\"No /Root object! - Is this really a PDF?\")\n",
      "pdfminer.pdfparser.PDFSyntaxError: No /Root object! - Is this really a PDF?\n",
      "PDF text extraction failed, skip text extraction...\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "No /Root object! - Is this really a PDF?\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 251, in partition_pdf_or_image\n",
      "    extracted_elements = extractable_elements(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 196, in extractable_elements\n",
      "    return _partition_pdf_with_pdfminer(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/utils.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 489, in _partition_pdf_with_pdfminer\n",
      "    elements = _process_pdfminer_pages(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/unstructured/partition/pdf.py\", line 561, in _process_pdfminer_pages\n",
      "    for i, page in enumerate(PDFPage.get_pages(fp)):  # type: ignore\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfpage.py\", line 154, in get_pages\n",
      "    doc = PDFDocument(parser, password=password, caching=caching)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bilalhashim/Desktop/LSE/Year 4/DS205/summative_project_2/problem-set-2-BilalNHashim/venv/lib/python3.12/site-packages/pdfminer/pdfdocument.py\", line 748, in __init__\n",
      "    raise PDFSyntaxError(\"No /Root object! - Is this really a PDF?\")\n",
      "pdfminer.pdfparser.PDFSyntaxError: No /Root object! - Is this really a PDF?\n",
      "PDF text extraction failed, skip text extraction...\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n",
      "Using starter code. Either edit this function or remove this warning if you are happy with the current implementation.\n"
     ]
    }
   ],
   "source": [
    "doc_text = {os.path.basename(file): utils.extract_text_data_from_pdf(file, unstructured_strategy=\"fast\") \n",
    "            for file in tqdm(files)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc_text is a dictionary within which each key is the document header, and the values are a list, where each element is a dict - where each dict basically represents an element and its respective metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Storing our doc_text dictionary as a pickle download so that we can recall without running the long above procedure__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"doc_text.pkl\", \"wb\") as f:\n",
    "    pickle.dump(doc_text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"doc_text.pkl\", \"rb\") as f:\n",
    "    doc_text = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already collect a lot of metadata about each chunk of PDF, as can be seen below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. docs: 186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 28,\n",
       " 'type': 'NarrativeText',\n",
       " 'text': 'Algeria is an African and a Mediterranean country covering 2 381 741 km2. Like many of the countries in its region, Algeria is affected by desertification and land degradation. Most of the country is arid or semi- arid. The areas receiving more than 400 mm of rain per year are located in a narrow strip along the coast, not-exceeding 150 km large. Moreover, due to climate changes, yearly average rainfall declined by more than 30% over the past decades.',\n",
       " 'metadata': {'page_number': 4,\n",
       "  'coordinates': CoordinatesMetadata(points=((70.824, 355.65031999999997), (70.824, 445.76935999999995), (527.73376, 445.76935999999995), (527.73376, 355.65031999999997)), system=<unstructured.documents.coordinates.PixelSpace object at 0x169752720>),\n",
       "  'file_directory': '../data/pdfs',\n",
       "  'filename': 'algeria_english_20220601.pdf',\n",
       "  'languages': ['eng'],\n",
       "  'last_modified': '2025-03-12T10:28:09',\n",
       "  'links': [],\n",
       "  '_known_field_names': frozenset({'attached_to_filename',\n",
       "             'category_depth',\n",
       "             'coordinates',\n",
       "             'data_source',\n",
       "             'detection_class_prob',\n",
       "             'detection_origin',\n",
       "             'emphasized_text_contents',\n",
       "             'emphasized_text_tags',\n",
       "             'file_directory',\n",
       "             'filename',\n",
       "             'filetype',\n",
       "             'header_footer_type',\n",
       "             'image_path',\n",
       "             'is_continuation',\n",
       "             'languages',\n",
       "             'last_modified',\n",
       "             'link_texts',\n",
       "             'link_urls',\n",
       "             'links',\n",
       "             'page_name',\n",
       "             'page_number',\n",
       "             'parent_id',\n",
       "             'regex_metadata',\n",
       "             'section',\n",
       "             'sent_from',\n",
       "             'sent_to',\n",
       "             'subject',\n",
       "             'text_as_html',\n",
       "             'url'}),\n",
       "  'parent_id': '39dac9a597eb80c4890adcd06690e2bc',\n",
       "  'filetype': 'application/pdf'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#186 documents \n",
    "print(f'No. docs: {len(doc_text)}')\n",
    "#From the algeria pdf for instance, we can extract the 23rd element which corresponds to a sentence on the 3rd page, if we extract the first element we see that this is the title \n",
    "doc_text['algeria_english_20220601.pdf'][28]\n",
    "#print(doc_text['algeria_english_20220601.pdf'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['democratic_republic_of_the_congo_french_20220601.pdf',\n",
       " 'argentina_spanish_20220501.pdf',\n",
       " 'georgia_english_20220601.pdf',\n",
       " 't√ºrkiye_english_20230401.pdf',\n",
       " 'canada_english_20250201.pdf',\n",
       " 'brazil_english_20241101.pdf',\n",
       " 'venezuela_(bolivarian_republic_of)_spanish_20220601.pdf',\n",
       " 'nauru_english_20220601.pdf',\n",
       " \"lao_people's_democratic_republic_english_20220601.pdf\",\n",
       " 'mali_french_20220601.pdf',\n",
       " 'morocco_french_20220601.pdf',\n",
       " 'zimbabwe_english_20250201.pdf',\n",
       " 'mauritania_french_20220601.pdf',\n",
       " 'new_zealand_english_20250101.pdf',\n",
       " 'marshall_islands_english_20250201.pdf',\n",
       " 'saudi_arabia_english_20211023.pdf',\n",
       " 'guatemala_spanish_20220601.pdf',\n",
       " 'mongolia_english_20220601.pdf',\n",
       " 'sao_tome_and_principe_english_20220601.pdf',\n",
       " 'guinea-bissau_english_20220601.pdf',\n",
       " 'equatorial_guinea_spanish_20221001.pdf',\n",
       " 'panama_spanish_20240601.pdf',\n",
       " 'vanuatu_english_20220801.pdf',\n",
       " 'andorra_spanish_20230101.pdf',\n",
       " 'burundi_french_20220601.pdf',\n",
       " 'bosnia_and_herzegovina_english_20220601.pdf',\n",
       " 'singapore_english_20221101.pdf',\n",
       " 'azerbaijan_english_20231001.pdf',\n",
       " 'solomon_islands_english_20220601.pdf',\n",
       " 'cambodia_english_20220601.pdf',\n",
       " \"c√¥te_d'ivoire_french_20220601.pdf\",\n",
       " 'australia_english_20220601.pdf',\n",
       " 'mozambique_english_20220601.pdf',\n",
       " 'tajikistan_english_20220601.pdf',\n",
       " 'kenya_english_20220601.pdf',\n",
       " 'united_kingdom_of_great_britain_and_northern_ireland_english_20250101.pdf',\n",
       " 'bahamas_english_20221101.pdf',\n",
       " 'syrian_arab_republic_english_20220601.pdf',\n",
       " 'kiribati_english_20230301.pdf',\n",
       " 'haiti_french_20220601.pdf',\n",
       " 'djibouti_english_20220601.pdf',\n",
       " 'dominica_english_20220701.pdf',\n",
       " 'malawi_english_20220601.pdf',\n",
       " 'grenada_english_20220601.pdf',\n",
       " 'peru_spanish_20220601.pdf',\n",
       " 'north_macedonia_english_20220601.pdf',\n",
       " 'ukraine_english_20220601.pdf',\n",
       " 'united_arab_emirates_english_20241101.pdf',\n",
       " 'cuba_english_20220601.pdf',\n",
       " 'holy_see_english_20230501.pdf',\n",
       " 'japan_english_20220601.pdf',\n",
       " 'sierra_leone_english_20220601.pdf',\n",
       " 'colombia_spanish_20220601.pdf',\n",
       " 'monaco_french_20220601.pdf',\n",
       " 'cabo_verde_english_20220601.pdf',\n",
       " 'el_salvador_spanish_20220601.pdf',\n",
       " 'trinidad_and_tobago_english_20220601.pdf',\n",
       " 'iceland_english_20220601.pdf',\n",
       " 'republic_of_korea_english_20220601.pdf',\n",
       " 'liechtenstein_english_20220601.pdf',\n",
       " 'saint_lucia_english_20250201.pdf',\n",
       " 'switzerland_english_20250101.pdf',\n",
       " 'nigeria_english_20220601.pdf',\n",
       " 'pakistan_english_20220601.pdf',\n",
       " 'rwanda_english_20220601.pdf',\n",
       " 'iraq_arabic_20220601.pdf',\n",
       " 'niue_english_20220601.pdf',\n",
       " 'belarus_english_20220601.pdf',\n",
       " 'chad_french_20220601.pdf',\n",
       " 'congo_french_20220601.pdf',\n",
       " 'zambia_english_20220601.pdf',\n",
       " 'mauritius_english_20220601.pdf',\n",
       " 'egypt_english_20230601.pdf',\n",
       " 'chile_spanish_20220601.pdf',\n",
       " 'kuwait_english_20220601.pdf',\n",
       " 'cuba_spanish_20250201.pdf',\n",
       " 'maldives_english_20250201.pdf',\n",
       " 'antigua_and_barbuda_english_20220601.pdf',\n",
       " 'turkmenistan_english_20230101.pdf',\n",
       " \"democratic_people's_republic_of_korea_english_20220601.pdf\",\n",
       " 'saint_vincent_and_the_grenadines_english_20220601.pdf',\n",
       " 'united_kingdom_of_great_britain_and_northern_ireland_english_20220901.pdf',\n",
       " 'russian_federation_english_20220601.pdf',\n",
       " 'singapore_english_20250201.pdf',\n",
       " 'palau_english_20220601.pdf',\n",
       " 'ecuador_spanish_20220601.pdf',\n",
       " 'bangladesh_english_20220601.pdf',\n",
       " 'nicaragua_spanish_20220601.pdf',\n",
       " 'montenegro_english_20220601.pdf',\n",
       " 'ethiopia_english_20220601.pdf',\n",
       " 'qatar_english_20220601.pdf',\n",
       " 'saint_kitts_and_nevis_english_20220601.pdf',\n",
       " 'dominican_republic_spanish_20220601.pdf',\n",
       " 'timor-leste_english_20221101.pdf',\n",
       " 'honduras_spanish_20220601.pdf',\n",
       " 'afghanistan_english_20220601.pdf',\n",
       " 'belize_english_20220601.pdf',\n",
       " 'uzbekistan_english_20220601.pdf',\n",
       " 'senegal_french_20220601.pdf',\n",
       " 'san_marino_english_20220601.pdf',\n",
       " 'south_sudan_english_20220601.pdf',\n",
       " 'uruguay_spanish_20221201.pdf',\n",
       " 'somalia_english_20220601.pdf',\n",
       " 'fiji_english_20220601.pdf',\n",
       " 'kazakhstan_english_20230601.pdf',\n",
       " 'united_republic_of_tanzania_english_20220601.pdf',\n",
       " 'algeria_english_20220601.pdf',\n",
       " 'oman_english_20231101.pdf',\n",
       " 'micronesia_(federated_states_of)_english_20221001.pdf',\n",
       " 'south_africa_english_20220601.pdf',\n",
       " 'zambia_english_20250301.pdf',\n",
       " 'costa_rica_spanish_20220601.pdf',\n",
       " 'angola_english_20220601.pdf',\n",
       " 'sudan_english_20221001.pdf',\n",
       " 'niger_french_20220601.pdf',\n",
       " 'benin_french_20220601.pdf',\n",
       " 'finland_english_20231001.pdf',\n",
       " 'china_english_20220601.pdf',\n",
       " 'sri_lanka_english_20220601.pdf',\n",
       " 'mexico_spanish_20221101.pdf',\n",
       " 'namibia_english_20240101.pdf',\n",
       " 'canada_english_20220601.pdf',\n",
       " 'cook_islands_english_20220601.pdf',\n",
       " 'republic_of_moldova_english_20220601.pdf',\n",
       " 'viet_nam_english_20221101.pdf',\n",
       " 'papua_new_guinea_english_20220601.pdf',\n",
       " 'india_english_20220801.pdf',\n",
       " 'togo_french_20220601.pdf',\n",
       " 'gambia_english_20220601.pdf',\n",
       " 'marshall_islands_english_20220601.pdf',\n",
       " 'zimbabwe_english_20220601.pdf',\n",
       " 'philippines_english_20220601.pdf',\n",
       " 'bhutan_english_20220601.pdf',\n",
       " 'eswatini_english_20220601.pdf',\n",
       " 'paraguay_spanish_20220601.pdf',\n",
       " 'bahrain_english_20220601.pdf',\n",
       " 'lesotho_english_20250201.pdf',\n",
       " 'central_african_republic_french_20220601.pdf',\n",
       " 'thailand_english_20221101.pdf',\n",
       " 'lebanon_english_20220601.pdf',\n",
       " 'guyana_english_20220601.pdf',\n",
       " 'kyrgyzstan_english_20220601.pdf',\n",
       " 'jordan_english_20220601.pdf',\n",
       " 'malaysia_english_20220601.pdf',\n",
       " 'gabon_french_20220701.pdf',\n",
       " 'tonga_english_20220601.pdf',\n",
       " 'nepal_english_20220601.pdf',\n",
       " 'uruguay_spanish_20250101.pdf',\n",
       " 'brunei_darussalam_english_20220601.pdf',\n",
       " 'guinea_french_20220601.pdf',\n",
       " 'maldives_english_20220601.pdf',\n",
       " 'cameroon_french_20220601.pdf',\n",
       " 'madagascar_french_20240101.pdf',\n",
       " 'norway_english_20221101.pdf',\n",
       " 'albania_english_20220801.pdf',\n",
       " 'montenegro_english_20250201.pdf',\n",
       " 'ecuador_spanish_20250201.pdf',\n",
       " 'serbia_english_20220801.pdf',\n",
       " 'armenia_english_20220601.pdf',\n",
       " 'ghana_english_20220601.pdf',\n",
       " 'tuvalu_english_20230201.pdf',\n",
       " 'japan_english_20250201.pdf',\n",
       " 'botswana_english_20241201.pdf',\n",
       " 'samoa_english_20220601.pdf',\n",
       " 'comoros_french_20220601.pdf',\n",
       " 'israel_english_20220601.pdf',\n",
       " 'suriname_english_20220601.pdf',\n",
       " 'eritrea_english_20220601.pdf',\n",
       " 'united_states_of_america_english_20220601.pdf',\n",
       " 'united_states_of_america_english_20241201.pdf',\n",
       " 'state_of_palestine_english_20220601.pdf',\n",
       " 'bolivia_(plurinational_state_of)_english_20220601.pdf',\n",
       " 'botswana_english_20220601.pdf',\n",
       " 'burkina_faso_french_20220601.pdf',\n",
       " 'switzerland_english_20241101.pdf',\n",
       " 'barbados_english_20220601.pdf',\n",
       " 'uganda_english_20220901.pdf',\n",
       " 'liberia_english_20220601.pdf',\n",
       " 'andorra_spanish_20250201.pdf',\n",
       " 'tunisia_french_20220601.pdf',\n",
       " 'myanmar_english_20220601.pdf',\n",
       " 'saint_lucia_english_20220601.pdf',\n",
       " 'jamaica_english_20220601.pdf',\n",
       " 'indonesia_english_20220901.pdf',\n",
       " 'seychelles_english_20220601.pdf',\n",
       " 'new_zealand_english_20220601.pdf']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lists all of our 186 document titles\n",
    "list(doc_text.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'type': 'Title',\n",
       " 'text': 'Rep√∫blica de Cuba',\n",
       " 'metadata': {'page_number': 1,\n",
       "  'coordinates': CoordinatesMetadata(points=((192.127, 238.42984), (192.127, 269.02084), (418.98985600000003, 269.02084), (418.98985600000003, 238.42984)), system=<unstructured.documents.coordinates.PixelSpace object at 0x2cc0c7380>),\n",
       "  'file_directory': '../data/pdfs',\n",
       "  'filename': 'cuba_spanish_20250201.pdf',\n",
       "  'languages': ['eng'],\n",
       "  'last_modified': '2025-03-12T10:21:24',\n",
       "  'links': [],\n",
       "  '_known_field_names': frozenset({'attached_to_filename',\n",
       "             'category_depth',\n",
       "             'coordinates',\n",
       "             'data_source',\n",
       "             'detection_class_prob',\n",
       "             'detection_origin',\n",
       "             'emphasized_text_contents',\n",
       "             'emphasized_text_tags',\n",
       "             'file_directory',\n",
       "             'filename',\n",
       "             'filetype',\n",
       "             'header_footer_type',\n",
       "             'image_path',\n",
       "             'is_continuation',\n",
       "             'languages',\n",
       "             'last_modified',\n",
       "             'link_texts',\n",
       "             'link_urls',\n",
       "             'links',\n",
       "             'page_name',\n",
       "             'page_number',\n",
       "             'parent_id',\n",
       "             'regex_metadata',\n",
       "             'section',\n",
       "             'sent_from',\n",
       "             'sent_to',\n",
       "             'subject',\n",
       "             'text_as_html',\n",
       "             'url'}),\n",
       "  'filetype': 'application/pdf'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_text['cuba_spanish_20250201.pdf'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Validation and Quality Assurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['morocco_french_20220601.pdf',\n",
       " 'kenya_english_20220601.pdf',\n",
       " 'kiribati_english_20230301.pdf',\n",
       " 'iraq_arabic_20220601.pdf',\n",
       " 'mauritius_english_20220601.pdf',\n",
       " \"democratic_people's_republic_of_korea_english_20220601.pdf\",\n",
       " 'marshall_islands_english_20220601.pdf',\n",
       " 'eswatini_english_20220601.pdf',\n",
       " 'paraguay_spanish_20220601.pdf',\n",
       " 'lesotho_english_20250201.pdf',\n",
       " 'israel_english_20220601.pdf',\n",
       " 'indonesia_english_20220901.pdf']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we attempt to see if there are any empty documents - if our parsing procedures worked properly we should not have any empty documents\n",
    "def extraction_validation(doc_text):\n",
    "    empty_docs = []\n",
    "    \n",
    "    for filename, chunks in doc_text.items():\n",
    "        if not chunks:\n",
    "            empty_docs.append((filename))\n",
    "            continue\n",
    "    return empty_docs\n",
    "\n",
    "extraction_validation(doc_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above procedure has identified that we do have several documents which were not parsed correctly, which may have been why we see errors in the top-most function. <BR>\n",
    "\n",
    "As these documents do not contain chunks they will not form part of our downstream RAG procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 docs are non-narrative heavy\n"
     ]
    }
   ],
   "source": [
    "# This function draws on the functionality provided by the unstructured package to recognise portions of the pdf\n",
    "# We check here to see if there are any documents that are not narrative dominant - this is important as we want to ensure that the documents we are working with have sufficient narrative text \n",
    "def flag_non_narrative_dominant_docs(doc_text, threshold=0.15):\n",
    "    flagged = []\n",
    "\n",
    "    for filename, chunks in doc_text.items():\n",
    "        narrative = [c for c in chunks if c.get(\"type\") == \"NarrativeText\"]\n",
    "        if len(narrative) / max(1, len(chunks)) < threshold:\n",
    "            flagged.append((filename, f\"{len(narrative)} of {len(chunks)} are narrative\"))\n",
    "    \n",
    "    return flagged\n",
    "\n",
    "print(f'{len(flag_non_narrative_dominant_docs(doc_text))} docs are non-narrative heavy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that because these documents do contain a variety of formats such as tables, headings etc. its normal to see several documents with low amount of narrative text which is why I set the threshold so low - and also undermines the extent to which this check is actually a highly robust screener given we do not have a benchmark to compare to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_documents = {}\n",
    "for doc, elements in doc_text.items():\n",
    "    chunked_documents[doc] = utils.chunk_document(doc_text[doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'line_number': 10,\n",
       " 'text': 'Target Years:',\n",
       " 'type': 'Title',\n",
       " 'metadata': {'page_number': 1,\n",
       "  'coordinates': CoordinatesMetadata(points=((72.024, 393.14199999999994), (72.024, 405.14199999999994), (135.14, 405.14199999999994), (135.14, 393.14199999999994)), system=<unstructured.documents.coordinates.PixelSpace object at 0x2f2615a30>),\n",
       "  'file_directory': '../data/pdfs',\n",
       "  'filename': 'afghanistan_english_20220601.pdf',\n",
       "  'languages': ['eng'],\n",
       "  'last_modified': '2025-03-12T10:28:10',\n",
       "  'links': [],\n",
       "  '_known_field_names': frozenset({'attached_to_filename',\n",
       "             'category_depth',\n",
       "             'coordinates',\n",
       "             'data_source',\n",
       "             'detection_class_prob',\n",
       "             'detection_origin',\n",
       "             'emphasized_text_contents',\n",
       "             'emphasized_text_tags',\n",
       "             'file_directory',\n",
       "             'filename',\n",
       "             'filetype',\n",
       "             'header_footer_type',\n",
       "             'image_path',\n",
       "             'is_continuation',\n",
       "             'languages',\n",
       "             'last_modified',\n",
       "             'link_texts',\n",
       "             'link_urls',\n",
       "             'links',\n",
       "             'page_name',\n",
       "             'page_number',\n",
       "             'parent_id',\n",
       "             'regex_metadata',\n",
       "             'section',\n",
       "             'sent_from',\n",
       "             'sent_to',\n",
       "             'subject',\n",
       "             'text_as_html',\n",
       "             'url'}),\n",
       "  'filetype': 'application/pdf'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_documents['afghanistan_english_20220601.pdf'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Docs with poor chunks: 174'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This chunking validation method is supposed to check just how many documents contain empty or short chunks at any one point\n",
    "def detect_poorly_chunked_docs(chunked_documents, min_length=10):\n",
    "    poorly_chunked_docs = []\n",
    "\n",
    "    for doc_id, chunks in chunked_documents.items():\n",
    "        for chunk in chunks:\n",
    "            text = chunk.get(\"text\", \"\")\n",
    "            if not isinstance(text, str) or len(text.strip()) < min_length:\n",
    "                poorly_chunked_docs.append(doc_id)\n",
    "                break \n",
    "\n",
    "    return(f\"Docs with poor chunks: {len(poorly_chunked_docs)}\")\n",
    "\n",
    "detect_poorly_chunked_docs(chunked_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Docs with poor chunks: 59317'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This builds on the last implementation by identifying the specific chunks that are empty or short and in turn how much of our chunks will be ineffective when it comes to embeddings\n",
    "def detect_empty_or_short_chunks(chunked_documents, min_length=10):\n",
    "    no_poor_chunks = []\n",
    "\n",
    "    for doc_id, chunks in chunked_documents.items():\n",
    "        for chunk in chunks:\n",
    "            text = chunk.get(\"text\", \"\")\n",
    "            if not isinstance(text, str) or len(text.strip()) < min_length:\n",
    "                no_poor_chunks.append(chunk)\n",
    "\n",
    "    return(f\"Docs with poor chunks: {len(no_poor_chunks)}\")\n",
    "\n",
    "detect_empty_or_short_chunks(chunked_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that nearly all of 186 documents contain at least 1 instance of either an empty chunk. This does not fully tell us the magnitude of the problem without the context of the second check <BR>\n",
    "\n",
    "Even more concerningly almost 60,000 of our c.190,000 chunks (or almost a third) are 'poor' quality. Of course some of these will not be poor and will just be short headers or titles or sentences etc. But for the most part we can imagine that these chunks will not be that useful when it comes to the rest of our pipeline.\n",
    "\n",
    "__Note: as I only impelmented these checks after completing the majority of this project I didn't get the chance to better engineer the chunk database - but this would have been a __major potential source of improvement for the project__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Comitting Chunks to our Database\n",
    "* This portion of the code was assisted heavily by vibe-coding. Nevertheless, the intuition behind this appraoch\n",
    "was to take our pre-processed document chunks and use SQLAlchemy to store them in our SQL database. <br>\n",
    "\n",
    "It starts with a helper function serialize_metadata() that makes sure the metadata attached to each chunk can be saved as JSON. I was having some problems uploading the frozensets, datetimes, and custom objects (like coordinates) datatypes, so this converts them into plain strings, lists, or dictionaries that can be safely stored. <br>\n",
    "\n",
    "For each document in chunked_documents, we strip the file extension from the document name (doc_id = doc_id[:-4]), this allows us to get the unique doc id which is the relational feature in this database <br>\n",
    "\n",
    "For each chunk, we generate a unique ID, serialize the metadata, building a dictionary with the relevant fields: id, doc_id, content, chunk_index, and chunk_metadata. <br>\n",
    "\n",
    "We call upon the DocChunk model inside of models.py script which is a SQLAlchemy model that represents each chunk, collects, and adds to the current session <br>\n",
    "\n",
    "Once all documents and their chunks are processed, we commits everything to the database with session.commit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Now you can import from climate_policy_extractor\n",
    "from climate_policy_extractor.models import get_db_session, DocChunk\n",
    "from dotenv import load_dotenv\n",
    "import uuid\n",
    "\n",
    "# Load environment variables and get database session\n",
    "load_dotenv()\n",
    "DATABASE_URL = os.getenv('DATABASE_URL')\n",
    "session = get_db_session(DATABASE_URL)\n",
    "session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import json\n",
    "import copy\n",
    "import datetime\n",
    "\n",
    "session.rollback()\n",
    "def serialize_metadata(metadata):\n",
    "    \"\"\"Convert metadata to JSON-serializable format.\"\"\"\n",
    "    if not metadata:\n",
    "        return None\n",
    "        \n",
    "    serialized = {}\n",
    "    for key, value in metadata.items():\n",
    "        if key == 'coordinates' and hasattr(value, 'points'):\n",
    "            # Convert coordinates to a list of lists\n",
    "            serialized[key] = {\n",
    "                'points': [list(point) for point in value.points],\n",
    "                'system': str(value.system)\n",
    "            }\n",
    "        elif key == '_known_field_names' and isinstance(value, frozenset):\n",
    "            # Convert frozenset to list\n",
    "            serialized[key] = list(value)\n",
    "        elif isinstance(value, (datetime, date)):\n",
    "            # Convert datetime/date to ISO format string\n",
    "            serialized[key] = value.isoformat()\n",
    "        elif isinstance(value, (list, tuple)):\n",
    "            # Convert lists/tuples to lists\n",
    "            serialized[key] = list(value)\n",
    "        else:\n",
    "            # For other types, try to convert to string if not already serializable\n",
    "            try:\n",
    "                json.dumps(value)\n",
    "                serialized[key] = value\n",
    "            except (TypeError, ValueError):\n",
    "                serialized[key] = str(value)\n",
    "    \n",
    "    return serialized\n",
    "\n",
    "# Process each document and its chunks\n",
    "for doc_id, chunks in chunked_documents.items():\n",
    "    doc_id = doc_id[:-4]\n",
    "    print(f\"Processing document: {doc_id}\")\n",
    "    \n",
    "    # Create DocChunk objects for each chunk\n",
    "    doc_chunks = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Serialize the metadata before creating the DocChunk\n",
    "        serialized_metadata = serialize_metadata(chunk.get('metadata', {}))\n",
    "        \n",
    "        # Create a dictionary with the chunk data\n",
    "        chunk_data = {\n",
    "            'id': chunk_id,\n",
    "            'doc_id': doc_id,\n",
    "            'content': chunk['text'],\n",
    "            'chunk_index': i,\n",
    "            'chunk_metadata': serialized_metadata\n",
    "        }\n",
    "        \n",
    "        # Create and add the DocChunk\n",
    "        doc_chunk = DocChunk(**chunk_data)\n",
    "        doc_chunks.append(doc_chunk)\n",
    "    \n",
    "    # Add all chunks to the session\n",
    "    session.add_all(doc_chunks)\n",
    "    print(f\"Added {len(doc_chunks)} chunks for document {doc_id}\")\n",
    "\n",
    "# Commit all chunks to the database\n",
    "session.commit()\n",
    "print(\"All chunks have been committed to the database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Chunking Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Another feature of this task was to improve upon the chunking strategy__, whilst I did experiment with this with the __aid of vibe-coding__, because of the time taken to generate embeddings on the new chunks, add these to the postgreSQL database, and then run similarity searches on the new embeddings I wasnt able to validate this function myself to see if it worked better and implement within my RAG pipeline <BR>\n",
    "\n",
    "However, I still thought I was include it in my project notebooks to demonstrate some of the increased efficiencies it brings and how I might look to use it if I carry this project forward independently. <BR>\n",
    "\n",
    "I kept the function definition inside of the utils.py file, with annotations of the changes made below as well as a working demonstration and comparison of the approach to the baseline <br>\n",
    "\n",
    "The original chunking strategy created one chunk per text element (e.g. paragraph), which led to many small or inconsistent chunks that harmed the semantic embedding quality and created too many chunks in the vector database. <BR>\n",
    "\n",
    "The new chunking strategy uses a rolling window within which:\n",
    "\n",
    "- Aggregates text into windows of up to 1000 characters \n",
    "- Uses a 200-character overlap between chunks to preserve semantic continuity\n",
    "- Produces context-rich chunks suitable for embedding and retrieval\n",
    "- Reduces the total number of chunks, improving both embedding efficiency and search performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chunked_documents = {}\n",
    "for doc, elements in doc_text.items():\n",
    "    new_chunked_documents[doc] = utils.improved_chunker(doc_text[doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'estation Plan with a global objective of reforestation of 1 245 000 ha. The mitigation actions to be implemented by Algeria, planned for the 2021-2030 period, will lead to the following contribution: Reduction of greenhouse gases emissions by 7% to 22%, by 2030, compared to a business as usual -BAU- scenario, conditional on external support in terms of finance, technology development and transfer, and capacity building. The 7% GHG reduction will be achieved with national means. The Algerian contribution regarding mitigation is defined as follows: Type of INDC: Relative reduction compared to Business as usual (BAU) scenario. Implementation period: 2021-2030 Methodological approach: combined approach: Bottom-Up concerning sectors and Top-Down concerning national objectives. Sectors covered: Energy (Generation, Transport, Building and Industry); Industrial processes; Agriculture, Forests, Land use and Waste. 6',\n",
       "  'chunk_index': 20},\n",
       " {'content': 'ncerning sectors and Top-Down concerning national objectives. Sectors covered: Energy (Generation, Transport, Building and Industry); Industrial processes; Agriculture, Forests, Land use and Waste. 6 Estimating GHG emissions: Directives of IPCC -2006- and Global Warming Potential, as agreed in the IPCC 4th Assessment Report on Climate change. Coverage of Greenhouse Gases: Carbon Dioxide (CO2), Methane (CH4), Nitrous Oxide (N2O). Global Warming Potential (GWP): the used GWP are those of the IPCC 4th Assessment Report: GWP (CO2) = 1, GWP (CH4)= 25, GWP (N2O)= 298. Implementation, monitoring and readjustment instruments: - National Climate Committee; - National Climate Change Agency; - National Climate Plan; - National Actions Plan for Environment and Sustainable Development ; - Legal framework; - National system of Measurement, Reporting and Verification -MRV- (2016-2020).',\n",
       "  'chunk_index': 21},\n",
       " {'content': 'ency; - National Climate Plan; - National Actions Plan for Environment and Sustainable Development ; - Legal framework; - National system of Measurement, Reporting and Verification -MRV- (2016-2020). Main planned actions: conditional on support in terms of external finance, technology development and transfer and capacity building. Operate an energy transition and an economic diversification to achieve Algeria‚Äôs sustainable development goals. Main Actions in Energy Sector: - Reach 27% of electricity generated from renewable sources of energy by 2030; - Generalize high-performance lighting; - Thermal insulation of buildings between 2021 and 2030; - Increase the share of liquefied petroleum and natural gas in the consumption of fuels between 2021 and 2030; - Reduce the volume of gas flaring to less than 1 % by 2030.',\n",
       "  'chunk_index': 22},\n",
       " {'content': 'ings between 2021 and 2030; - Increase the share of liquefied petroleum and natural gas in the consumption of fuels between 2021 and 2030; - Reduce the volume of gas flaring to less than 1 % by 2030. Main Actions in Waste Sector: - Waste valorization ; - Composting organic waste and green waste; - Energy recovery and recycling of methane from landfill sites and waste water treatment plants. Main Actions in forestry Sector: afforestation, reforestation and prevention of forest fires as well as improving means to fight them. Awareness, Information and Education Actions: Information, awareness and communication on issues and climate change challenges and implementation of an education, training and research climate change national program. 7 Considerations of fairness and ambition of the INDC based on national circumstances',\n",
       "  'chunk_index': 23},\n",
       " {'content': 'mate change challenges and implementation of an education, training and research climate change national program. 7 Considerations of fairness and ambition of the INDC based on national circumstances Algeria, as a low GHG emitting country, has already invested heavily in adaptation to climate change impacts as well as in mitigation and intends to pursue its efforts in this regard; Algeria has been participating since a long period of time in the greenhouse gas mitigation, by virtue of its high share of natural gas in its energy mix; The Algerian economy is highly dependent on petroleum export revenues. This situation makes Algeria vulnerable to climate change adverse effects, as well as to the negative impacts of response measures; Algeria faces significant and growing development and adaptation needs given its high population growth, increasing demand for energy, goods and services.',\n",
       "  'chunk_index': 24},\n",
       " {'content': 'o the negative impacts of response measures; Algeria faces significant and growing development and adaptation needs given its high population growth, increasing demand for energy, goods and services. How INDC will contribute to the accomplishment of article 2 of the Convention on Climate Change Through its mitigation actions for by 2030, considering its socio-economic development objectives, and taking into account its national circumstances, Algeria will contribute, on an equitable basis, to the achievement of the objective of article 2 of the Convention. 5. Adaptation Measures Algeria aims to develop a national plan of adaptation to the impacts of climate change in the context of the finalization of its contribution, and in order to promote a more c l i m a t e c h a n g e resilient economy. Priority will be given to the protection of the population and the preservation of natural resources and key infrastructure against the risks of extreme events.',\n",
       "  'chunk_index': 25},\n",
       " {'content': 'm a t e c h a n g e resilient economy. Priority will be given to the protection of the population and the preservation of natural resources and key infrastructure against the risks of extreme events. The objective of this national plan is: To reinforce the ecosystems resilience (flooding and drought) in order to curtail the risks of natural disasters related to climate change; To fight against erosion and rehabilitate its degraded lands as part of t h e e f f o r t s t o combat desertification ; To integrate the impacts of climate change into sectorial strategies, in particular for agriculture, water management, public health and transport; To integrate the impacts of climate change on political stability and national security. 8 The main adaptation measures to be adopted require diversified international support, including financing, capacity-building and technology transfer. These adaptation measures mentioned in the National Climate Plan are as follows:',\n",
       "  'chunk_index': 26},\n",
       " {'content': 'be adopted require diversified international support, including financing, capacity-building and technology transfer. These adaptation measures mentioned in the National Climate Plan are as follows: Adapting the institutional and regulatory framework to climate change; - Reinforcing institutional and human capacities in combating climate change; - Establishing a monitoring and early warning system and capacity building with regard to extreme climate events management; Elaborating regional and local plans for adaptation to climate change. 6. Planning and Institutional Framework for Implementation The provisional intended and nationally determined contribution will be finalized between 2016 and 2020 under the authority of the National Climate Committee. It will be updated according to the outcomes of the Paris Climate Conference and will take into account the financial situation of Algeria at the moment of its finalization.',\n",
       "  'chunk_index': 27},\n",
       " {'content': 'tional Climate Committee. It will be updated according to the outcomes of the Paris Climate Conference and will take into account the financial situation of Algeria at the moment of its finalization. It will address quantified greenhouse gas mitigation objectives for the period 2020- 2030, using the methodology developed by the Intergovernmental Panel on Climate Change. The contribution will be finalized and implemented with the active participation of all the actors in the society and, in particular, representatives of the civil society, economic actors, representatives of the local authorities and the scientific community. It will be accompanied by a comprehensive public awareness-raising campaign through the media, schools, companies, local collectivities and mosques. In this regard, forums on cities and climate change will be set up.',\n",
       "  'chunk_index': 28},\n",
       " {'content': 'anied by a comprehensive public awareness-raising campaign through the media, schools, companies, local collectivities and mosques. In this regard, forums on cities and climate change will be set up. Algeria‚Äôs ambition regarding mitigation and adaptation will be achieved within North- South and South-South cooperation, with its bilateral and multilateral- traditional and new- partners. A group of ‚ÄúFriends of Algeria‚Äôs Ambition for Adaptation and Mitigation‚Äù (G5A), will be established and convene its first meeting on the sidelines of the Paris Conference. Finally, Algeria aims to establish and host a World Forum on Renewable Energy that will provide the appropriate platform for dialogue and consultation between policy- makers, industry and civil society. The first session of the Forum will be held in 2016. Its outcomes will be presented at the 22nd Conference of the Parties. Conclusion',\n",
       "  'chunk_index': 29}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 5 chunks of the first document\n",
    "new_chunked_documents['algeria_english_20220601.pdf'][20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately these chunks might have been __too__ long compared to the previous chunking strategy - however this is an easy fix by changing the default chunk length in the function within utils. It would have been interesting to see how this chunk length affected the embeddings vectors produced in the next notebook, and in turn the retrieval stage of my pipeline however as mentioned I wasn't able to implement due to time constraints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
