{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB-04 Evaluation \n",
    "\n",
    "### In this notebook I take the responses that we gathered from the LLM and evaluate how successfully my project achieved the spec task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_responses = pickle.load(open(\"llm_responses.pkl\", \"rb\"))\n",
    "llm_responses_empty_countries = pickle.load(open(\"llm_responses_non_retrieved_countries.pkl\", \"rb\"))\n",
    "complete_embeddings_df = pickle.load(open(\"complete_embeddings_df.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import pandas as pd\n",
    "\n",
    "all_llm_responses = {**llm_responses, **llm_responses_empty_countries}\n",
    "\n",
    "llm_df = pd.DataFrame([\n",
    "    {\"country\": country, \"llm_response\": response}\n",
    "    for country, response in all_llm_responses.items()\n",
    "])\n",
    "\n",
    "llm_df = pd.DataFrame([{\"country\": country, \"llm_response\": response} for country, response in all_llm_responses.items()])\n",
    "\n",
    "def extract_citations(text):\n",
    "    pattern = r\"\\[Doc ID: (.*?), Chunk ID: (\\d+)\\]\"\n",
    "    return re.findall(pattern, text)\n",
    "\n",
    "llm_df[\"citations\"] = llm_df[\"llm_response\"].apply(extract_citations)\n",
    "\n",
    "# We drop any rows if they do not have citations \n",
    "exploded = llm_df.explode(\"citations\").dropna(subset=[\"citations\"])\n",
    "\n",
    "exploded[[\"doc_id\", \"chunk_index\"]] = pd.DataFrame(exploded[\"citations\"].tolist(), index=exploded.index)\n",
    "exploded[\"chunk_index\"] = exploded[\"chunk_index\"].astype(int)\n",
    "\n",
    "merged_df = pd.merge(exploded, complete_embeddings_df,on=[\"doc_id\", \"chunk_index\"],how=\"left\")\n",
    "\n",
    "merged_df = merged_df.drop(columns=[\"citations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We eneded up with 59 countries for which our robust RAG pipeline delivered results\n",
    "len(merged_df['country_x'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [],\n",
       " 'filename': 'bangladesh_english_20220601.pdf',\n",
       " 'filetype': 'application/pdf',\n",
       " 'languages': ['eng'],\n",
       " 'parent_id': '663ea1bfffe5038f3f0cf667f14c4257',\n",
       " 'coordinates': {'points': [[265.25, 541.20112],\n",
       "   [265.25, 605.16112],\n",
       "   [514.08088, 605.16112],\n",
       "   [514.08088, 541.20112]],\n",
       "  'system': '<unstructured.documents.coordinates.PixelSpace object at 0x2b8bbd790>'},\n",
       " 'page_number': 30,\n",
       " 'last_modified': '2025-03-12T10:27:13',\n",
       " 'file_directory': '../data/pdfs',\n",
       " '_known_field_names': ['page_number',\n",
       "  'parent_id',\n",
       "  'links',\n",
       "  'filetype',\n",
       "  'last_modified',\n",
       "  'link_texts',\n",
       "  'attached_to_filename',\n",
       "  'sent_to',\n",
       "  'url',\n",
       "  'link_urls',\n",
       "  'regex_metadata',\n",
       "  'coordinates',\n",
       "  'section',\n",
       "  'sent_from',\n",
       "  'data_source',\n",
       "  'text_as_html',\n",
       "  'emphasized_text_tags',\n",
       "  'category_depth',\n",
       "  'header_footer_type',\n",
       "  'detection_class_prob',\n",
       "  'filename',\n",
       "  'languages',\n",
       "  'subject',\n",
       "  'emphasized_text_contents',\n",
       "  'detection_origin',\n",
       "  'image_path',\n",
       "  'is_continuation',\n",
       "  'page_name',\n",
       "  'file_directory']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['chunk_metadata'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_fields(metadata):\n",
    "    try:\n",
    "        page = metadata.get(\"page_number\")\n",
    "        coords = metadata.get(\"coordinates\", {}).get(\"points\")\n",
    "        filename = metadata.get(\"filename\")\n",
    "        return pd.Series([page, coords, filename])\n",
    "    except Exception:\n",
    "        return pd.Series([None, None, None])\n",
    "\n",
    "merged_df[[\"page_number\", \"coordinate_points\", \"source_filename\"]] = merged_df[\"chunk_metadata\"].apply(extract_metadata_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
