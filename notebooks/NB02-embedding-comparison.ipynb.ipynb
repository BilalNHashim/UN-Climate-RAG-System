{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB2: Embeddings - Implementation & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Implementation:__\n",
    "    - Compare keyword search (creative use of Word2Vec or of things like bag-of-words and TF-IDF) [__INCOMPLETE__]\n",
    "    - Compare it with Transformer-generated embeddings[__INCOMPLETE__]\n",
    "\n",
    "    __Course References: W7 Lecture: Word2Vec models, W8 Lecture: Transformer models__\n",
    "\n",
    "* __Analysis:__\n",
    "    - Exploratory analysis of embedding spaces (e.g., pairwise similarity, visualisation) [__INCOMPLETE__]\n",
    "    - Document discovery of insights (or lack of) from exploration [__INCOMPLETE__]\n",
    "    - Document performance differences\t[__INCOMPLETE__]\n",
    "\n",
    "    __Course References: W8 Lecture: Embedding visualization, W8 Lab: HuggingFace ecosystem__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc_text is a dictionary within which each key is the document header, and the values are a list, where each element is a dict - where each dict basically represents an element and its respective metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3257580433.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mimport 'NB01-pdf-extractor'\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from utils import chunk_document\n",
    "\n",
    "import nbimporter\n",
    "import NB01_pdf_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_documents = {}\n",
    "for doc, elements in doc_text.items():\n",
    "    chunked_documents[doc] = chunk_documents(doc_text[doc])\n",
    "\n",
    "chunked_documents \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
